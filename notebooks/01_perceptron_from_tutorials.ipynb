{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb4eec47-992f-44f0-b75b-1ab63544bb2c",
   "metadata": {},
   "source": [
    "# Premières implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8584cc-20d7-40ac-91c2-f7b9590602bb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9abd77-3134-43ad-a37f-11594149be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c2718-566f-4185-a771-c3ec91df0e25",
   "metadata": {},
   "source": [
    "## Tutoriel #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d581cf-5dab-435d-9a0c-d95c881727f3",
   "metadata": {},
   "source": [
    "[Perceptron Algorithm with Code Example - ML for beginners!](https://www.youtube.com/watch?v=-KLnurhX-Pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cccf26-62c5-45ff-a4c7-817b9c35e80a",
   "metadata": {},
   "source": [
    "### Composantes du perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68252176-ee6c-4d27-a363-d6b1fb574f3a",
   "metadata": {},
   "source": [
    "On dispose des données d'entrée $(x_{i})_{i=1,...,n}$ auquelles sont associés des poids $(w_{i})_{i=1,...,n}$ qui représentent l'importance relative de chaque $x_i$ les iuns par rapport aux autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda03959-1838-4df0-8240-fbcbbe2d58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "x_input = [0.1,0.5,0.2]\n",
    "\n",
    "# Weights\n",
    "w_weights = [0.4,0.3,0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e09deb-168d-45ad-93ff-be1b287d062a",
   "metadata": {},
   "source": [
    "On effectue la somme pondérée des données d'entrée $ \\sum_{i}^{n}x_{i}\\times\\omega_{i}$ et on veut évaluer si cette somme, appelée biais,  atteint un certain seuil. Pour vérifier cela, on utilise une fonction d'activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a83d4-eddf-4330-a70b-4be9c4dc975e",
   "metadata": {},
   "source": [
    "Seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cfe9cb-cf39-49ed-8f62-29fd2acc19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88216f-150a-4286-8c83-45fb0471bfee",
   "metadata": {},
   "source": [
    "Fonction d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbffd79e-267c-40cb-a78e-906c014718d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(weighted_sum):\n",
    "    return 1 if weighted_sum>threshold else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7746a-2598-4898-a3bc-47e9dd83631f",
   "metadata": {},
   "source": [
    "$ \\sum_{i}^{n}x_{i}\\times\\omega_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9acadea-f421-4251-8017-88af7efc0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron():\n",
    "    weighted_sum = 0\n",
    "    for x,w in zip(x_input,w_weights):\n",
    "        weighted_sum += x*w\n",
    "        print(weighted_sum)\n",
    "    return activation_function(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e083b3b-fea7-4811-9a6b-9553afc9a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04000000000000001\n",
      "0.19\n",
      "0.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508475c1-ff54-4fa4-97c1-a34b3bfd4605",
   "metadata": {},
   "source": [
    "## Tutoriel #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b874f9-f19c-4971-85b2-08c285337f0f",
   "metadata": {},
   "source": [
    "[Gradient Descent - Simply Explained! ML for beginners with Code Example!](https://www.youtube.com/watch?v=jwStsp8JUPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91713655-edd4-4f07-aef5-18b32c3f61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "features =[[0.1,0.5,0.2],\n",
    "           [0.2,0.3,0.1],\n",
    "           [0.4,0.1,0.2],\n",
    "           [0.4,0.1,0.3]]\n",
    "\n",
    "# Targets\n",
    "targets = [0,1,0,1]\n",
    "\n",
    "# Weights\n",
    "w_weights = [0.4,0.2,0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e11f54-76a5-473e-9faa-2b803f56bd13",
   "metadata": {},
   "source": [
    "La fonction d'activation utilisée sera la fonction sigmoïde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346d893d-e6b8-4f7c-8a6e-4b4184f29873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return round(1/(1+np.exp(-x)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebdb772-ebd6-4004-b11e-0540ef0daad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.0 : 0.01\n",
      "-4.0 : 0.02\n",
      "-3.0 : 0.05\n",
      "-2.0 : 0.12\n",
      "-1.0 : 0.27\n",
      "0.0 : 0.5\n",
      "1.0 : 0.73\n",
      "2.0 : 0.88\n",
      "3.0 : 0.95\n",
      "4.0 : 0.98\n",
      "5.0 : 0.99\n"
     ]
    }
   ],
   "source": [
    "for x in np.linspace(-5,5,11): \n",
    "    print(x,\":\",sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a1464-17e8-4a31-b8fd-3e43e0b58324",
   "metadata": {},
   "source": [
    "On n'effectue plus seulement la somme pondérée des données d'entrée, on y ajoute un biais : $ \\sum_{i}^{n}x_{i}\\times\\omega_{i} + bias$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73061770-f53c-484b-a15e-276d52bcb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias\n",
    "bias = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5cf04-fd42-4581-86d3-4a7d905f08a1",
   "metadata": {},
   "source": [
    "On introduit une fonction de coût ou perte qui permettra de mesurer l'éloignement entre la valeur prédite et la valeur à prédire.\n",
    "Ici ce sera la cross entropie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55595113-426c-40c1-8f0c-62e373f45eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(target,pred):\n",
    "    return -((1-target)*(np.log10(1-pred)) + (target * np.log10(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53408975-aa77-480b-ac6b-6647a5fbad72",
   "metadata": {},
   "source": [
    "### &Eacute;tapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f89d47-6c06-4556-9a8a-6df79eb5ab03",
   "metadata": {},
   "source": [
    "On traîte de l'individu #0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd276407-d9c3-4e9d-9e51-64989ccd0942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.1, 0.5, 0.2], 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0], targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae81413-12df-4de4-81ad-d7b1ccf05dc3",
   "metadata": {},
   "source": [
    "On calcule la somme pondérée de ses composantes (variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d0602e-c456-4a41-acaf-61a3cff61c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = sum([x*w for x,w in zip(features[0],w_weights)]) + bias\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa450e-ce69-4833-b2b0-1005712ae8ca",
   "metadata": {},
   "source": [
    "On applique la fonction d'activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4b0be38-79c8-4ae1-a063-40e2f8b2f428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = sigmoid(weighted_sum)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c958a-5d44-48bd-8ab6-de8457c4a55d",
   "metadata": {},
   "source": [
    "On calcule la distance entre la valeur prédite pour l'individu #0 et la cible #0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c81722-1e72-4055-8f4a-b2a1ee963f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49485002168009407"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_loss = cross_entropy_loss(targets[0],pred)\n",
    "individual_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274547f8-9db2-4fa7-90b5-4bf8f44272ed",
   "metadata": {},
   "source": [
    "**Descente de gradient**\n",
    "\n",
    "On définit un pas d'apprentissage (learning rate).\n",
    "\n",
    "<u>Mise à jour des poids.</u>\n",
    "\n",
    "$new\\_weight_i = weigth_i + learning\\_rate \\times (target-pred) \\times x_i$\n",
    "\n",
    "autrment dit :\n",
    "\n",
    "$w_i' =  w_i + \\alpha \\times (y-\\hat{y}) \\times x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac11383-754e-4880-9c10-d750662744e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de1e59c8-4150-4d17-9c97-4d92235ad591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 : 0.3932\n",
      "0.2 : 0.166\n",
      "0.6 : 0.5864\n"
     ]
    }
   ],
   "source": [
    "for w,x in zip(w_weights,features[0]):\n",
    "    old_w = w\n",
    "    w += learning_rate * (targets[0]-pred) * x\n",
    "    print(old_w,\":\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25015f2-bda9-4d68-9f99-1e2e550249f1",
   "metadata": {},
   "source": [
    "<u>Mise à jour du biais.</u>\n",
    "\n",
    "$new\\_bias = bias + learning\\_rate \\times (target-pred)$\n",
    "\n",
    "autrment dit :\n",
    "\n",
    "$b' =  b + \\alpha \\times (y-\\hat{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5b97f11-01a6-40ce-bb59-44fc6ad30d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.432"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias += learning_rate * (targets[0]-pred)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd5789-fe9f-4425-b452-fd973759acbf",
   "metadata": {},
   "source": [
    "On répète le processus sur l'ensemble des individus. Une itération s'appelle une **époque**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c41ad-5e0a-460e-9c2f-f8f4eeed33ac",
   "metadata": {},
   "source": [
    "### Itération d'une époque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc958a27-61a0-48f3-b23f-36d418424f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "features =[[0.1,0.5,0.2],\n",
    "           [0.2,0.3,0.1],\n",
    "           [0.7,0.4,0.2],\n",
    "           [0.1,0.4,0.3]]\n",
    "\n",
    "# Targets\n",
    "targets = [0,1,0,1]\n",
    "\n",
    "# Weights\n",
    "w_weights = [0.4,0.2,0.6]\n",
    "\n",
    "# Bias\n",
    "bias = 0.5\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd9963f6-3d55-48a8-9009-d9ff6f9793f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights : [0.4, 0.2, 0.6] Initial bias : 0.5\n",
      "\n",
      "0 [0.1, 0.5, 0.2] 0.76 0.68 0.49485002168009407\n",
      "loss : 0.49485002168009407\n",
      "Updated weights : [0.3932, 0.166, 0.5864]\n",
      "Updated bias: 0.432\n",
      "\n",
      "1 [0.2, 0.3, 0.1] 0.61908 0.65 0.18708664335714442\n",
      "loss : 0.18708664335714442\n",
      "Updated weights : [0.4002, 0.17650000000000002, 0.5899]\n",
      "Updated bias: 0.46699999999999997\n",
      "\n",
      "2 [0.7, 0.4, 0.2] 0.93572 0.72 0.5528419686577808\n",
      "loss : 0.5528419686577808\n",
      "Updated weights : [0.3498, 0.14770000000000003, 0.5755]\n",
      "Updated bias: 0.39499999999999996\n",
      "\n",
      "3 [0.1, 0.4, 0.3] 0.66171 0.66 0.1804560644581313\n",
      "loss : 0.1804560644581313\n",
      "Updated weights : [0.3532, 0.16130000000000003, 0.5857]\n",
      "Updated bias: 0.42899999999999994\n",
      "\n",
      "0.3538086745382876\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial weights :\",w_weights,\"Initial bias :\",bias)\n",
    "print()\n",
    "losses = []\n",
    "for i,feature in enumerate(features):\n",
    "    weighted_sum = sum([x*w for x,w in zip(feature,w_weights)]) + bias\n",
    "    pred = sigmoid(weighted_sum)\n",
    "    loss = cross_entropy_loss(targets[i],pred)\n",
    "    losses.append(loss)\n",
    "    print(i, feature,weighted_sum,pred,loss)\n",
    "    step = learning_rate * (targets[i]-pred)\n",
    "    bias += step\n",
    "    for j,x in enumerate(feature):    \n",
    "        w_weights[j] += step * x\n",
    "\n",
    "    print(\"loss :\",losses[i])\n",
    "    print(\"Updated weights :\",w_weights)\n",
    "    print(\"Updated bias:\",bias)\n",
    "    print()\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e19ae40b-ea87-4a69-b99e-ad99d9679a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42899999999999994"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6421e2e8-d1d6-499d-9c0e-42435de01e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron():\n",
    "    weighted_sum = 0\n",
    "    for x,w in zip(x_input,w_weights):\n",
    "        weighted_sum += x*w\n",
    "        print(weighted_sum)\n",
    "    weighted_sum += bias\n",
    "    print(weighted_sum)\n",
    "    return sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84dd4-5f68-4c0f-841a-331b1ce87426",
   "metadata": {},
   "source": [
    "### Implémentation complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2477925-0c19-496b-932b-123025371008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "features = np.array([[0.1,0.5,0.2],\n",
    "                     [0.2,0.3,0.1],\n",
    "                     [0.4,0.1,0.2],\n",
    "                     [0.4,0.1,0.3]])\n",
    "\n",
    "# Targets\n",
    "targets = np.array([0,1,0,1])\n",
    "\n",
    "# Weights\n",
    "w_weights = np.array([0.4,0.2,0.6])\n",
    "\n",
    "# Bias\n",
    "bias = 0.5\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e3879d7-b9d1-475b-863a-e609587bdb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "# Get Model output\n",
    "def get_prediction(features, weights, bias):\n",
    "    weighted_sum = np.dot(features,weights) + bias\n",
    "    return sigmoid(weighted_sum)\n",
    "    \n",
    "# Loss function\n",
    "def cross_entropy_loss(target,pred):\n",
    "    return -((1-target)*(np.log10(1-pred)) + (target * np.log10(pred)))\n",
    "\n",
    "# Update weights\n",
    "def gradient_descent(feature, target, pred, weights, bias, learning_rate):\n",
    "    step = learning_rate * (target-pred)\n",
    "    bias += step \n",
    "    new_weights = w_weights + step * feature\n",
    "    return new_weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37040e7e-b370-49b2-a005-6f60981fac2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 :  loss=0.3005940346505341\n",
      "Epoch #1 :  loss=0.2973711286893814\n",
      "Epoch #2 :  loss=0.2946898964372144\n",
      "Epoch #3 :  loss=0.29246346836674836\n",
      "Epoch #4 :  loss=0.2906173794067871\n",
      "Epoch #5 :  loss=0.2890883139733882\n",
      "Epoch #6 :  loss=0.28782279417780277\n",
      "Epoch #7 :  loss=0.28677589689135846\n",
      "Epoch #8 :  loss=0.2859100525986449\n",
      "Epoch #9 :  loss=0.28519395477265425\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for i, feature in enumerate(features):\n",
    "        target = targets[i]\n",
    "        pred = get_prediction(feature,target,bias)\n",
    "        losses.append(cross_entropy_loss(target,pred))\n",
    "        w_weights, bias = gradient_descent(feature, target,pred, w_weights,bias,learning_rate)\n",
    "    print(f\"Epoch #{epoch} :  loss={np.mean(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fa21b-01b9-4e34-ad79-5372f8504f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
